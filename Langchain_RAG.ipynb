{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "552z_qTqP6oT"
      },
      "outputs": [],
      "source": [
        "pip install -q --upgrade langchain langchain-openai langchain-core langchain_community langchain_chroma sentence_transformers docx2txt pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "id": "zPVFbk-iQKOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "open_ai_key = os.getenv(\"OPENAI_API_KEY\") or userdata.get(\"OPENAI_API_KEY\")\n",
        "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\") or userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "#print(open_ai_key)\n",
        "#print(langchain_api_key)\n"
      ],
      "metadata": {
        "id": "TnNhTXpxQOwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'langchain-rag'\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key"
      ],
      "metadata": {
        "id": "9zN0a32TQX2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tracers.context import tracing_v2_enabled\n",
        "\n",
        "# with tracing_v2_enabled():\n",
        "#   llm_resonse = llm.invoke(query_to_llm)"
      ],
      "metadata": {
        "id": "W3KykUfAQqg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "FZiyapnKRB1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "\n",
        "\n",
        "# pdf_loader = PyPDFLoader(\"/content/documents/Generative AI.pdf\")\n",
        "# documents = pdf_loader.load()\n",
        "\n",
        "# splits = text_splitter.split_documents(documents)\n",
        "\n",
        "# print(f'Document splitted into {len(splits)} chunks')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t9rVkVJbR0ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(splits[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WTwISK2eU7hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(splits[0].metadata)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "47Wh8-ZqU8Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(splits[0].page_content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eFFUgllaVDwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split / Chunking\n",
        "\n",
        "# function to fetch all files from documents folder\n",
        "def fetch_files(path: str) -> List[Document]:\n",
        "  documents = []\n",
        "  for file_name in os.listdir(path):\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    if file_name.endswith(\".pdf\"):\n",
        "      loader = PyPDFLoader(file_path)\n",
        "    elif file_name.endswith(\".docx\"):\n",
        "      loader = Docx2txtLoader(file_path)\n",
        "    else:\n",
        "      print(f'Unsupported file type: {file_name}')\n",
        "      continue\n",
        "    documents.extend(loader.load())\n",
        "  return documents\n",
        "\n",
        "\n",
        "path = '/content/documents'\n",
        "documents = fetch_files(path)\n",
        "\n",
        "print(f'Loaded {len(documents)} documents from folder.')\n",
        "\n",
        "splits = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f'Document splitted into {len(splits)} chunks')"
      ],
      "metadata": {
        "id": "zfRXE9JKUoO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "document_embeddings = embedding_function.embed_documents([split.page_content for split in splits])\n",
        "\n",
        "document_embeddings[0]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wUIfpL41X2PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Store in Vector DB\n",
        "\n",
        "# from langchain_chroma import Chroma\n",
        "\n",
        "# openai_embedding = OpenAIEmbeddings()\n",
        "# collection_name = 'apple_hig_documents'\n",
        "# vector_store = Chroma.from_documents(documents=splits, embedding=openai_embedding, collection_name=collection_name)\n",
        "\n",
        "# print('Vector store created and persisted to \"./chroma_db\"')"
      ],
      "metadata": {
        "id": "WARa06vWY4I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Etp9AvljVV_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "persist_dir = 'chroma_db'\n",
        "vector_store = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding_model,\n",
        "    collection_name='apple_hig_documents',\n",
        "    persist_directory=persist_dir\n",
        ")\n",
        "print('Vector store created and persisted to \"chroma_db\"')"
      ],
      "metadata": {
        "id": "nqyh3g7lVZY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform similarty search\n",
        "\n",
        "quey = 'You can position toolbar items in which three locations?'\n",
        "\n",
        "seatch_results = vector_store.similarity_search(quey, k=4)\n",
        "\n",
        "print(f'\\nTop 4 most relevant chunks for the query: \"{quey}\"\\n')\n",
        "for index, result in enumerate(seatch_results):\n",
        "  print(f'Result {index}')\n",
        "  print(f'Source: {result.metadata.get('source', 'Unknown')}')\n",
        "  print(f'Content: {result.page_content}')\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nM88034SXPrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import search\n",
        "retriever = vector_store.as_retriever(search_kwargs={'k': 4})\n",
        "retriever.invoke('You can position toolbar items in which three locations?')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "m5311LEcXku1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "template = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "qGYjKvOoZJI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {'context': retriever, 'question': RunnablePassthrough()}\n",
        "    | prompt\n",
        "    #| ChatOpenAI(temperature=0)\n",
        ")\n",
        "rag_chain.invoke('You can position toolbar items in which three locations?')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9-A48paqZiyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doctToStr(docs):\n",
        "  return '\\n\\n'.join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "-cthw86na742"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {'context': retriever | doctToStr, 'question': RunnablePassthrough()}\n",
        "    | prompt\n",
        ")\n",
        "rag_chain.invoke('You can position toolbar items in which three locations?')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EZbKw-Q5bJsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing output\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "#output_parser.invoke(llm_resonse)\n"
      ],
      "metadata": {
        "id": "PyQQg1eOcYEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "YfnCMr-4ctrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {'context': retriever | doctToStr, 'question': RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "question = 'You can position toolbar items in which three locations?'\n",
        "response = rag_chain.invoke(question)\n",
        "print(f'Question: {question}\\n')\n",
        "print(f'Answer: {response}')\n"
      ],
      "metadata": {
        "id": "iSsz19lzbvlI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}